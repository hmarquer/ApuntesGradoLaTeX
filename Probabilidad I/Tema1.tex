\section{Tema 1: Sucesos y probabilidades}
\subsection{Formalizando}
\begin{defn}[Espacio muestral]
	En un experimento aleatorio, el espacio muestral es el conjunto (no vacío) de sus posibles resultados y se denota por $\Omega$. Puede ser:
	\begin{enumerate}[topsep=1pt, itemsep=1pt,parsep=3pt]
		\item Finito: $\Omega = \{\omega_1, \dots, \omega_N\}$
		\item Infinito numerable: $\Omega = \{\omega_1, \omega_2, \dots\}$
		\item Infinito no numerable, ej.: $\Omega = \left[0, 1\right) \ve \Omega =
			      \mathcal{P}\left(\left[0, 1\right)\right)$
	\end{enumerate}
\end{defn}
\begin{defn}[Espacio de sucesos por Kolmogórov]
	Dado el espacio muestral $\Omega$ de un experimento aleatorio, $\F \subset \mathcal{P}(\Omega)$ es su espcio de sucesos
	\[\iff \left(\F \ne \phi\right) \we \left(A \in \F \implies A^C \in \F\right) \we \left(A_1,A_2, \dots \in \F \implies \bigcup_{j=1}^{\infty} A_j \in \F\right)\]
\end{defn}

\begin{obs}
	De la definición se deduce: \\
	\centerline{
		\begin{itemize*}[itemjoin=\hspace{1cm}]
			\item $\ds \phi \in \F \we \Omega \in \F$
			\item $\ds A_1, \dots, A_n \in \F \implies \bigcup_{j=1}^{n} A_j \in \F$
			\item $\forall A, B \in \F \implies A\cap B \in \F$
		\end{itemize*}
	}
\end{obs}

\begin{defn} [Función o medida de probabilidad]
	Dados espacio muestral $(\Omega)$ y de sucesos $(\F)$ de un experimento aleatorio, la aplicación $\appl{P}{\F}{[0, 1]} : $ es una medida de probabilidad
	\[ \iff \left(P(\Omega) = 1\right) \we \left[P\left(\bigcup_{j=1}^{\infty} A_j\right) = \sum_{j=1}^{\infty} P(A_j) \iff A_i\cap A_j = \phi \tex{ cuando } i \ne j\right] \]
\end{defn}
\begin{prop}
	De la definición se deduce: \\
	\begin{enumerate*}[itemjoin=\hspace{1cm}]
		\item $\ds P\left(\bigcup_{j=1}^n A_j\right) = \sum_{j=1}^{n} P(A_j)$
		\item $\ds P\left(A^C\right) = 1-P(A)$
		\item $\ds P(\phi) = 0$ \\
		\item $\ds P(A\cup B) = P(A) + P(B) - P(A\cap B)$
		\item $\ds A \subseteq B \implies P(A) \leq P(B)$
	\end{enumerate*}
\end{prop}

\begin{ejem}
	En un experimento aleatorio con espacio muestral finito, tomamos \\
	$\ds \Omega = \{\omega_1, \dots, \omega_N\}  \we \F = \mathcal{P} \rightarrow 2^N$. Asignamos $\ds P(\{\omega_j\}) = p_j \we j = 1, \dots, N$ tales que $\ds p_j\geq 0 \we \sum_{j=1}^{N} p_j = 1$. Entonces, $\ds\forall A \in \F : P(A) = \sum_{\omega \in A} P(\omega)$ \\
	\textbf{Caso particular: }$\ds \forall j \in \N_N : p_j = \frac{1}{N} \implies \forall A \in \F : P(A) = \frac{|A|}{N} = \frac{\tex{``Casos favorables''}}{\tex{``Total de casos''}}$
\end{ejem}
\fecha{05/02/2024}
\textbf{Ejemplos varios:}
\begin{enumerate}%[Ejemplos]
	\item (Muy tonto) $\ds\Omega \ne \phi$, tomas $\ds A \subset \Omega : A\ne \phi, \Omega$. \\
	      Dato $\ds p\in (0, 1)$. $\ds\F = \{\phi, A, A^c, \Omega\}$ con $\ds P(A) = p$.
	\item (Bastante general) $\ds\left(\Omega = \{\omega_1, \dots, \omega_N\} \implies |\Omega| = N\right) \we \left(\F = P(\Omega) \rightarrow |\F|=2^N\right)$. \\
	      Dato: $\ds p_1, \dots, p_N \ge 0 \implies \sum_{j=1}^N p_j=1$.
	      Asignamos $\ds \forall j\in \N_N : p_j\defeq P(\{\omega_j\})$.\\
	      Definimos $\ds \forall A\subset \Omega : P(A) = \sum_{\omega \in A}P(\omega)$.\\
	\item Lanzas $n$ veces una moneda. Dato: $p \in (0,1)$.
	      \[\implies \Omega = \{111\cdots1, \dots, 000\cdots0\} \we |\Omega|=2^N \we \tex{escogemos } \F=P(\Omega)\]
	      \[\implies \forall \omega \in \Omega : P(\omega)= p^{\#\tex{unos de }\omega} (1-p)^{\#\tex{ceros de }\omega}\]
	      Comprobamos:
	      \begin{equation*}
		      \begin{split}
			      \ds\sum_{\omega \in \Omega} P(\omega) & =\sum_{k=0}^n \left(\sum_{\substack{\omega\in \Omega                                         \\
			      \#\tex{0s de }\omega = k}} P(\omega)\right)=\sum_{k=0}^n p^k (1-p)^{n-k}\left(|\{\omega\in \Omega :\#\tex{1s de } \omega=k\}|\right) \\
			                                            & =\sum_{k=0}^np^k(1-p)^{n-k} \binom{n}{k} = (p+1-p)^n=1
		      \end{split}
	      \end{equation*}
	\item Lanzamos moneda hasta que sale una cara. Dato $\ds p\in (0,1)$.
	      \[\implies \Omega = \{C, XC, XXC, \dots\} \we \tex{escogemos } \F=P(\Omega)\]
	      \[P(C)\eqdef p \implies P(XC)=p(1-p) \we P(XXC)=p(1-p)^2 \we \dots\]
	      Comprobamos: $\ds\sum_{j=1}^{\infty} p(1-p)^{j-1} = p\sum_{k=0}^\infty(1-p)^k =
		      p \frac{1}{1-(1-p)} = 1$
\end{enumerate}

\subsection{Probabilidad condicionada y total, independencia y Bayes}
Tienes $(\Omega, \F, P)$ y un suceso $A\in \F \rightarrow P(A)$. Llega ``nueva
información'': ha ocurrido el suceso $B\in F \longrightarrow$ ¿Debo reasignar
la probabilidad de $A$?
\begin{ejem}[Dependencia]
	Lanzas 10 veces una moneda (regular).
	\[A=\{\tex{salen 6 caras}\} \implies P(A)=\frac{\binom{10}{6}}{2^{10}} \approx 20.51 \%\]
	\[B=\{\tex{sale C en 1º}\} \implies P(A)\tex{ sube a }\frac{\binom{9}{5}}{2^9}\]
\end{ejem}

\begin{defn}
	Sea $(\Omega, \F, P)$ un espacio de probabilidad y los sucesos $A, B \in \F : P(B)>0$, $P(A|B)$ es la probabilidad de $A$ condicionada a $B$
	\[\iff P(A|B)=\frac{P(A\cap B)}{P(B)}\]
	\begin{obs}
		En general, $P(A|B)\ne P(B|A)$
	\end{obs}
\end{defn}
\begin{prop}[Cálculo de $P(A|B)$ para cada $A \in \F$]
	Sea $(\Omega, \F, P)$ un espacio de probabilidad y $B \in \F$ un suceso con $P(B)>0$
	\[\implies (\Omega, \F, Q_B) \tex{, con } \appl{Q_B}{\F}{\left[0,1\right]}:Q_B(A)=P(A|B) \tex{, es un espacio de probabilidad}\]
	\begin{dem}
		Basta ver que $Q_B$ es una función de probabilidad.
		\[\left(Q_B(A)=P(A|B)=\frac{P(A\cap B)}{P(B)} \in \left[0, 1\right]\right) \we \left(Q_B(\Omega)=\frac{P(\Omega\cap B)}{P(B)}=\frac{P(B)}{P(B)}=1\right)\]
		Sean $A_1, A_2, \dots \in \F$ disjuntos dos a dos.
		\begin{equation*}
			\begin{split}
				\implies Q_B\left(\bigcup_{j=1}^\infty A_j\right) & =P\left(\bigcup_{j=1}^\infty A_j\;\middle|\; B\right)=\frac{P\left(\bigcup_{j=1}^\infty A_j \cap B\right)}{P(B)}                         \\
				                                                  & =\frac{1}{P(B)}P\left(\bigcup_{j=1}^\infty (A_j \cap B)\right)=\frac{1}{P(B)}\sum_{j=1}^\infty P(A_j\cap B) = \sum_{j=1}^\infty Q_B(A_j)
			\end{split}
		\end{equation*}
	\end{dem}
\end{prop}

\begin{defn}[Independencia]
	Sean $A,B \in \F$ dos sucesos con $P(A), P(B) \geq 0$ son independientes
	\[\iff P(A|B) = P(A) \we P(B|A)=P(B) \textit{ (para entender)}\]
	\[\iff P(A\cap B)=P(A)\cdot P(B) \textit{ (la adecuada)}\]
	\begin{itemize}[topsep=1pt, itemsep=1pt,parsep=3pt]
		\item $A, B$ disjuntos $\implies$ no independientes.
		\item $A_1, \dots, A_N \in \F$ independientes $\ds \iff \forall J \subset \N_N: P\left(\bigcap_{j\in I} A_j\right)=\prod_{j\in J}P(A_j)$ \\
		      $\ds \iff P\left(\overline{A_1}\cap\cdots\cap\overline{A_N}\right)=\prod_{i=1}^N P\left(\overline{A_i}\right)$ donde $\overline{A_i}=A_i, (A_i)^c$
	\end{itemize}
\end{defn}
\begin{ejer}
	Encontrar un espacio de probabilidad en el que haya un conjunto de sucesos independientes dos a dos pero no completamente independientes.
	\[\textbf{SOL: }\Omega = \{1, 2, 3, 4\} \we A=\{1, 2\} \we B=\{2, 3\} \we C=\{1,3\}\]
\end{ejer}

\begin{prop}[Regla de Bayes]
	Sean $(\Omega, \F, P)$ un espacio de probabilidad y $A, B \in \F$ sucesos con $P(A), P(B)>0$
	\[\implies P(A|B)=P(B|A)\cdot \frac{P(A)}{P(B)}\]
	\begin{dem}
		\[P(A|B)=\frac{P(A\cap B)}{P(B)} \we P(B|A)=\frac{P(A\cap B)}{P(A)}\]
		\[\implies P(A|B)\cdot P(B) = P(A\cap B) = P(B|A)\cdot P(A) \implies P(A|B)=P(B|A)\cdot \frac{P(A)}{P(B)}\]
	\end{dem}
\end{prop}

\subsubsection{Probabilidad total}
\begin{prop}
	Sean $(\Omega, \F, P)$ un espacio de probabilidad y $\{B_1, B_2, \dots\}$ una partición de $\ds \Omega : \left(\forall i, j :  i\ne j : B_i\cap B_j = \phi\right) \we \left(\bigcup_{j=1}^\infty B_j=\Omega\right)$
	\[\implies \forall A \in \F : P(A)=P\left(\bigcup_{j=1}^\infty(A\cap B_j)\right)=\sum_{j=1}^\infty(A\cap B_j)=\sum_{j=1}^\infty P(A|B_j)\cdot P(B_j)\]
	\[\implies \forall A \in \F : \boxed{P(A) = \sum_{j=1}^\infty P(A|B_j)\cdot P(B_j)}\]
	\hfill \qedsymbol
\end{prop}
\begin{ejem}
	Sean $U_1=\{10b, 3n\} \we U_2=\{5b, 5n\} \we U_3=\{2b, 6n\}$ tres urnas con bolas blancas ($b$) y negras ($n$). Procedimiento:
	\begin{enumerate}[topsep=1pt, itemsep=1pt,parsep=3pt]
		\item Sorteamos una urna $P(U_1)=\frac{1}{4} \we P(U_2)=\frac{1}{4} \we P(U_3) =
			      \frac{1}{2}$
		\item Sacamos bola de la urna seleccionada.
	\end{enumerate}
	¿Cuál es la probabilidad de que sea blanca?
	\[P(b)=P(b|U_1)P(U_1)+P(b|U_2)P(U_2)+P(b|U_3)P(U_3)\]
\end{ejem}

\begin{ejem}[Peso de la evidencia]
	Sean $U_1=\{80\%\,b, 20\%\,n\} \we U_2=\{20\%\,b, 80\%\,n\}$ dos urnas con bolas blancas ($b$) y negras ($n$). Procedimiento:
	\begin{enumerate}[topsep=1pt, itemsep=1pt,parsep=3pt]
		\item Sorteamos la urna con $\sfrac{1}{2}$ y $\sfrac{1}{2}$ de probabilidad.
		\item Sacamos $10$ bolas (con reemplazamiento).
	\end{enumerate}
	Observamos la evidencia: $bb\dots nb$ ¿qué urna se usó?
	\[P(U_1|5b5n)=P(5b5n|U_1)\frac{P(U_1)}{P(5b5n)}=\frac{P(5b5n|U_1)P(U_1)}{P(5b5n|U_1)P(U_1)+P(5b5n|U_2)P(U_2)}\]
	\[\implies P(5b5n|U_1)=\binom{10}{5}0.8^50.2^5=P(5b5n|U_2) \implies P(U_1|5b5n)=\frac{1}{2}\]
	Este es el resultado que esperábamos, prestemos atención a otro caso más
	contraintituitivo.
	\[\begin{aligned}
			P(U_1|6b4n) & = \frac{P(6b4n|U_1)P(U_1)}{P(6b4n|U_1)P(U_1)+P(6b4n|U_2)P(U_2)}                                                                                   \\
			            & = \frac{\binom{10}{6}0.8^60.2^4\cdot\sfrac{1}{2}}{\binom{10}{6}0.8^60.2^4\cdot\sfrac{1}{2} + \binom{10}{6}0.8^40.2^6\cdot\sfrac{1}{2}}\approx90\%
		\end{aligned}\]
\end{ejem}
\begin{wrapfigure}{r}{4.3cm}
	\includesvg[width=4cm]{img/graph1.svg}
\end{wrapfigure}

Si dibujamos la gráfica de la función \[ f(x)=P(U_1 | xb(10-x)n)\] podemos ver que el cambio es muy brusco. Es decir, una pequeña diferencia en la
evidencia puede cambiar mucho la probabilidad de que se haya usado una urna u
otra.

\begin{ejem}[Falsos positivos/negativos]
	Hay una enfermedad $(E \ve S)$ y hay una prueba para detectar $(+ \ve -)$. Datos: $P(+ | E)=95\% \we P(-| S)=99\%$.\\
	Te haces la prueba y sale $+$:
	\[P(E|+)=P(+|E)\frac{P(E)}{P(+)}=\frac{P(+|E)P(E)}
		{P(+|E)P(E)+P(+|S)P(S)}\]
	Conozco todas estas probabilidades excepto $p\defeq P(E) \implies P(S)=1-p$.
\end{ejem}
\begin{wrapfigure}{l}{3.2cm}
	\vspace{-0.85cm}
	\includesvg[width=3cm]{img/graph2.svg}
\end{wrapfigure}
Si definimos $f(p)\defeq P(E|+)$ \[\implies \{f(0.5)=98.95\% \we f(\sfrac{1}{100}) = 48.97\%\we f(\sfrac{1}{1000}) = 8.68\% \}\]
Es decir, si la incidencia es muy baja, no tiene sentido hacer pruebas
masivamente porque la mayoría de positivos serán falsos.

\begin{ejem}[Sobre independencia]
	$(\Omega, \F, P) \we A_1, \dots, A_n$ sucesos independientes tal que $\forall j \in \N_n : P(A_j)=\frac{1}{n}$. ¿Qué sabemos sobre $\ds P\left(\bigcup_{j=1}^n A_j\right)$?
	\[\tex{En general, sabemos que } \frac{1}{n}\leq P\left(\bigcup_{j=1}^n A_j\right) \leq \sum_{j=1}^nP(A_j)\leq 1\]
	$n=2$: $\ds P(A\cup B)=P(A)+P(B)-P(A\cap B)=\sfrac{3}{4}$ \\
	$n=3$: $\ds P(A\cup B\cup C)=\binom{3}{1}\frac{1}{3}-\binom{3}{2}\frac{1}{3^2}+\binom{3}{3}\frac{1}{3^3}=\sfrac{19}{27}$ \\
	$n$ general: $\ds P\left(\bigcup_{j=1}^n A_j\right)=\sum_{j=1}^nP(A_j)-\sum_{1\leq i<y\leq n} P(A_i\cap A_j) + \cdots$ (Inclusión exclusión)
	\[\implies P\left(\bigcup_{j=1}^n A_j\right)= \binom{n}{1}\frac{1}{n} - \binom{n}{2}\frac{1}{n^2} + \binom{n}{3}\frac{1}{n^3} + \cdots=\sum_{j=1}^n\binom{n}{j}\frac{1}{n^j}(-1)^{j+1}\]
	\[\implies P\left(\bigcup_{j=1}^n A_j\right)= 1-\sum_{j=0}^n\binom{n}{j}\left(\frac{-1}{n}\right)^j=1-\left(1-\frac{1}{n}\right)^n\xrightarrow{n\rightarrow\infty}1-\frac{1}{e}\]
\end{ejem}

\subsubsection{Continuidad de la probabilidad: detalle técnico}

\begin{prop}
	Sean $(\Omega, \F, P)$ un espacio de probabilidades y $ A_1, \dots : A_1 \subset A_2 \subset \cdots$ una sucesión creciente de conjuntos
	\[\implies P\left(\bigcup_{j=1}^\infty A_j\right)=\lim_{n\rightarrow\infty}P\left(A_n\right)\]
	\begin{dem}
		Se trata de describir $\bigcup_{j=1}^n A_j$ como la unión de conjuntos disjuntos.
		\[P\left(\bigcup_{j=1}^n A_j\right)=P\left(A_1\cup\bigcup_{j=1}^{n-1} \left(A_{j+1}\setminus A_j\right)\right)=P(A_1)+\sum_{j=1}^{n-1}\left(P(A_{j+1})-P(A_j)\right)=P(A_n)\]
		\[\implies P\left(\bigcup_{j=1}^\infty A_j\right) = P(A_1)+\sum_{j=1}^{\infty}\left(P(A_{j+1})-P(A_j)\right)=\lim_{n\rightarrow\infty}P(A_n)\]
	\end{dem}
\end{prop}

%12/02/2024
\begin{prop}
	Si la sucesión $A_1, \dots$ es decreciente
	$\ds\implies P\left(\bigcap_{j=1}^\infty A_j\right)=\lim_{n\rightarrow\infty}P\left(A_n\right)$
\end{prop}

\begin{teo}[Continuidad de la probabilidad]
	En el espacio de probabilidades $(\Omega, \F, P)$, sea $A_1, A_2, \dots$ una sucesión $: \forall j \in \N : A_j \in \F$
	\[\implies P\left(\bigcup_{j=1}^\infty A_j\right)=\lim_{n\rightarrow\infty}P\left(\bigcup_{j=1}^n A_j\right)\]
	\begin{dem}
		Definimos $\ds B_i\defeq\bigcup_{j=1}^i A_j \implies \bigcup_{j=1}^\infty A_j = \bigcup_{i=1}^\infty B_i \we (B_i)$ es creciente.
		\[\implies P\left(\bigcup_{j=1}^\infty A_j\right) = P\left(\bigcup_{i=1}^\infty B_i\right) = \lim_{n\rightarrow\infty}P\left(B_n\right)=P\left(\bigcup_{j=1}^n A_j\right)\]
	\end{dem}
\end{teo}

